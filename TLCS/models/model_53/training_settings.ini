[simulation]
gui = False
total_episodes = 100
total_episodes_per_worker = 25
max_steps = 5400
n_cars_generated = 200
green_duration = 10
yellow_duration = 4

[model]
num_layers = 4
width_layers = 400
batch_size = 100
learning_rate = 0.001
training_epochs = 800

[memory]
memory_size_min = 600
memory_size_max = 50000

[agent]
num_states = 80
num_actions = 4
gamma = 0.75
algorithm = PPO    ; Change this to "DQN" if you want to run the DQN agent instead

[ppo]
hidden_size = 64
learning_rate = 0.001
clip_ratio = 0.2
update_epochs = 10

[a3c]
hidden_size = 64
learning_rate = 0.0005

[dir]
models_path_name = models
sumocfg_file_name = sumo_config.sumocfg
